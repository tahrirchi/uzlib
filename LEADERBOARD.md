# UzLiB Leaderboard

| **Model Name** | **Organization** | **All** | **Correct word** | **Meaning** | **Meaning in context** | **Fill in** |
|:--------------:|:----------------:|:-------:|:----------------:|:-----------:|:----------------------:|:-----------:|
| [Gemini 2.5 Pro](https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-pro) | Google | **0.6905** | **0.6795** | **0.7627** | **0.7778** | **0.5577** |
| [Claude 3.7 Sonnet](https://www.anthropic.com/news/claude-3-7-sonnet) | Anthropic | 0.6513 | 0.6429 | 0.7246 | 0.7083 | 0.4808 |
| [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) | Anthropic | 0.6362 | 0.6442 | 0.5975 | 0.7222 | 0.4615 |
| [GPT 4o](https://platform.openai.com/playground/chat?models=gpt-4o-2024-11-20) | OpenAI | 0.6319 | 0.6376 | 0.6059 | 0.6528 | **0.5577** |
| [Gemini 2.5 Flash](https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash) | Google | 0.6255 | 0.6409 | 0.555 | 0.6389 | 0.4808 |
| [GPT 5](https://platform.openai.com/playground/chat?models=gpt-5) | OpenAI | 0.6158 | 0.6322 | 0.5763 | 0.5417 | 0.4231 |
| [Gemini 2.0 Flash](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-001) | Google | 0.6013 | 0.6029 | 0.5593 | 0.7361 | **0.5577** |
| *Human voters＊* | - | *0.5894* | *0.6054* | *0.5247* | *0.5254* | *0.5094* |
| [Gemini 2.0 Flash Lite](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-lite-001) | Google | 0.5862 | 0.6036 | 0.5085 | 0.5833 | 0.4423 |
| [Gemini 2.5 Flash Lite Preview](https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-lite-preview-06-17) | Google | 0.5605 | 0.5803 | 0.5042 | 0.5 | 0.3269 |
| [Llama 4 Scout](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct) | Meta | 0.5519 | 0.5736 | 0.4703 | 0.5556 | 0.2885 |
| [gpt-oss-120b](https://huggingface.co/openai/gpt-oss-120b) | OpenAI | 0.5492 | 0.5743 | 0.4576 | 0.3611 | 0.5 |
| [DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324) | DeepSeek | 0.5443 | 0.551 | 0.5212 | 0.5278 | 0.4808 |
| [GPT 5 mini](https://platform.openai.com/playground/chat?models=gpt-5-mini) | OpenAI | 0.5293 | 0.5423 | 0.5 | 0.4861 | 0.3462 |
| [GPT 4o mini](https://platform.openai.com/playground/chat?models=gpt-4o-mini-2024-07-18) | OpenAI | 0.5255 | 0.5410 | 0.4915 | 0.4306 | 0.3654 |
| [Kimi K2](https://huggingface.co/moonshotai/Kimi-K2-Instruct) | Moonshot AI | 0.518 | 0.5376 | 0.4492 | 0.4722 | 0.3269 |
| [Grok 3](https://x.ai/news/grok-3) | xAI | 0.5148 | 0.5083 | 0.5678 | 0.5833 | 0.3654 |
| [Claude Sonnet 4](https://www.anthropic.com/news/claude-4) | Anthropic | 0.5046 | 0.5283 | 0.4703 | 0.1944 | 0.4038 |
| [Gemma 3 27B](https://huggingface.co/google/gemma-3-27b-it) | Google | 0.4949 | 0.5177 | 0.4237 | 0.3889 | 0.3077 |
| [GPT 5 nano](https://platform.openai.com/playground/chat?models=gpt-5-nano) | OpenAI | 0.4927 | 0.525 | 0.3475 | 0.4028 | 0.3462 |
| [Qwen3-235B-A22B-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507) | Alibaba | 0.4874 | 0.5043 | 0.4364 | 0.3889 | 0.3654 |
| [Claude Sonnet 4.5 Sonnet](https://www.anthropic.com/news/claude-sonnet-4-5) | Anthropic | 0.4847 | 0.5083 | 0.4407 | 0.25 | 0.3269 |
| [Gemma 3 12B](https://huggingface.co/google/gemma-3-12b-it) | Google | 0.468 | 0.491 | 0.3814 | 0.4444 | 0.2308 |
| [gpt-oss-20b](https://huggingface.co/openai/gpt-oss-20b) | OpenAI | 0.4578 | 0.4837 | 0.3898 | 0.3056 | 0.2308 |
| [Qwen3 32B](https://huggingface.co/Qwen/Qwen3-32B) | Alibaba | 0.4562 | 0.4724 | 0.4025 | 0.3611 | 0.3654 |
| [Gemma 3n](https://aistudio.google.com/prompts/new_chat?model=gemma-3n-e4b-it) | Google | 0.4369 | 0.4624 | 0.3432 | 0.3472 | 0.25 |
| [Llama 3.3 70B](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) | Meta | 0.4293 | 0.447 | 0.3602 | 0.3889 | 0.2885 |
| [Mistral 7B Uz](https://huggingface.co/behbudiy/Mistral-7B-Instruct-Uz) | Behbudiy Labs | 0.4202 | 0.4364 | 0.3559 | 0.3333 | 0.3654 |
| [Command A](https://huggingface.co/CohereForAI/c4ai-command-a-03-2025) | Cohere | 0.4186 | 0.4277 | 0.3771 | 0.3889 | 0.3846 |
| [Mistral Nemo](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407) | Mistral AI | 0.4095 | 0.4344 | 0.2881 | 0.3611 | 0.3077 |
| [Qwen3 8B](https://huggingface.co/Qwen/Qwen3-8B) | Alibaba | 0.3853 | 0.3997 | 0.2924 | 0.3611 | 0.4231 |
| [Mistral Nemo Uz](https://huggingface.co/behbudiy/Mistral-Nemo-Instruct-Uz) | Behbudiy Labs | 0.3799 | 0.3951 | 0.2966 | 0.4167 | 0.2692 |
| [Llama 3.1 8B](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct) | Meta | 0.3745 | 0.3937 | 0.3051 | 0.3472 | 0.1731 |
| [Qwen3 14B](https://huggingface.co/Qwen/Qwen3-14B) | Alibaba | 0.374 | 0.3797 | 0.3771 | 0.3194 | 0.2692 |
| [Phi 4](https://huggingface.co/microsoft/phi-4) | Microsoft | 0.3401 | 0.3471 | 0.322 | 0.2361 | 0.3654 |
| [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) | Mistral AI | 0.3246 | 0.3431 | 0.2542 | 0.2639 | 0.1923 |
| [Llama 3.2 3B Uz](https://huggingface.co/bxod/Llama-3.2-3B-Instruct-uz) | Bekhzod Shukhratov | 0.2832 | 0.2805 | 0.2712 | 0.3194 | 0.3654 |
| [Llama 4 Maverick](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct) | Meta | 0.281 | 0.2658 | 0.3644 | 0.2917 | 0.3269 |
| [Llama 3.1 8B Uz](https://huggingface.co/behbudiy/Llama-3.1-8B-Instuct-Uz) | Behbudiy Labs | 0.2773 | 0.2851 | 0.25 | 0.2361 | 0.2308 |
| [Llama 3.2 3B](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct) | Meta | 0.2671 | 0.2758 | 0.25 | 0.2083 | 0.1731 |
| *Random Baseline* | - | *0.25* | *0.25* | *0.25* | *0.25* | *0.25* |
| [Llama 3.2 1B Uz](https://huggingface.co/bxod/Llama-3.2-1B-Instruct-uz) | Bekhzod Shukhratov | 0.2456 | 0.2552 | 0.2288 | 0.1389 | 0.1923 |
| [Llama 3.2 1B](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) | Meta | 0.2332 | 0.2285 | 0.25 | 0.25 | 0.2692 |

* ＊ Human voters score is not the average of humans doing all the questions but the average of accuracy score for each question. Also, note that random baseline for humans is 0.4229 due to variable number of options (2-3) in the original questions.